# Video-Captioning-Using-LSTM-and-Keras

Video Captioning is an encoder decoder mode based on sequence to sequence learning. It takes a video as input and generates a caption describing the event in the video.

The importance of captioning lies in its ability to make video more accessible in numerous ways. 
Automated video caption generator helps searching of videos in websites better. 
It can be used for clustering of videos based on their content easier.
This is a brief overview of my project. To understand the project in details check out my medium <a href="https://medium.com/analytics-vidhya/video-captioning-with-keras-511984a2cfff">post</a>. I also did a <a href="https://youtu.be/DJEnkhKPbxA">live session</a> on this you can check that as well.

## Table of contents
* <a href="#Inspiration">Inspiration</a>
* <a href="#SampleResults">Sample Results</a>
* <a href="#Dataset">Dataset</a>
* <a href="#Setup">Setup</a>
* <a href="#Usage">Usage</a>
* <a href="#Model">Model</a>
  * <a href="#TrainingArchitecture">Training Architecture</a>
  * <a href="#InferenceArchitecture">Inference Architecture</a>
  * <a href="#Loss">Loss</a>
  * <a href="#Metric">Metric</a>
* <a href="#Features">Features</a>
* <a href="#Scripts">Scripts</a>
* <a href="#FutureDevelopment">Future Development</a>
* <a href="#References">References</a>

